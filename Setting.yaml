Geolife:

  dataset: Geolife
  out_dir: 'ModelSave'
  result_dir: 'SimpTraj'
  nostdout: True
  gpu: 1
  seed: 0


  load_grid: False
  minlon: 115.7001
  minlat: 39.4
  maxlon: 117.39994
  maxlat: 41.59471
  maxseqlen: 5000
  minseqlen: 500
  Xmin: 39.477849
  Ymin: 115.7097866
  Tmin: 1176587085
  step: 100

  minfreq: 50
  max_grid_size: 20000
  k: 1
  grid_start: 4

  max_length: 500
  overlap: 100
  load_graph: True
  load_emb: True


  gridemb_dim: 128
  context_size: 10
  walks_per_node: 10
  walk_length: 80
  num_workers: 2
  gridemb_lr: 0.01
  gridemb_epochs: 1000


  n_train_start: 0
  n_train: 1000
  max_train_len: 2000

  batch_size: 32
  device: 'cpu'

  Bert:
    encoding_type: 'temporal'
    tbert_num_layers: 4
    tbert_num_heads: 8
    tbert_mask_prop: 0.2
    tbert_detach: False
    tbert_objective: 'mlm'
    tbert_static: False
    embed_size: 128
    max_seq_len: 500
    init_param: False
    embed_epoch: 2000
    grid_size: 20004
    pretain_path: './ModelSave/Geolife/pretrain/Bert_100_100_50_20000'
    device: 'cpu'

  GAT:
    in_features: 128
    out_features: 32
    num_heads: 4
    lr: 1e-4
    wd: 0.0
    batch_size: 64
    num_epoch: 20
    lambda1: 0.3
    lambda2: 0.5
    lambda3: 1
    save_path: './ModelSave/Geolife/GraphSimp_100_100_50_20000'

  Diff:

    wd: 0.0
    batch_size: 64


    schedule_sampler: "uniform"
    lr: 1e-4
    ema_rate: "0.9999" # comma-separated list of EMA values
    log_interval: 50
    save_interval: 50000
    resume_checkpoint: ""
    use_fp16: False
    fp16_scale_growth: 1e-3
    weight_decay: 0.0
    lr_anneal_steps: 0
    checkpoint_path: 'diff_models'
    gradient_clipping: -1.0
    eval_interval: 2000
    epochs: 20
    lambda1: 0.7

    in_dim: 4
    encoder_n_head: 2
    encoder_hidden_dim: 128
    encoder_n_layer: 2
    in_channels: 128
    hidden_channels: 256
    out_channels: 128
    n_head: 2
    n_layer: 2
    trans_hidden_channels: 256
    attn_dropout: 0.1
    dropout: 0.1

    learn_sigma: False
    sigma_small: False
    diffusion_steps: 2000
    noise_schedule: 'linear'
    timestep_respacing: ''
    use_kl: False
    predict_xstart: False
    rescale_timesteps: True
    rescale_learned_sigmas: True
    training_mode: 'e2e'

    amplify_len: 20
    diff_step_eval: 500


  ad_ratio: 0.5
  cr: [0.0025,0.003,0.0035,0.004,0.0045,0.01,0.02]
  mutual_epochs: 10



T-drive:

  dataset: T-drive
  out_dir: 'ModelSave'
  result_dir: 'SimpTraj'
  nostdout: True
  gpu: 0
  seed: 0


  load_grid: True
  minlon: 115.7001
  minlat: 39.4
  maxlon: 117.39994
  maxlat: 41.59471
  maxseqlen: 5000
  minseqlen: 500
  Xmin: 39.40238
  Ymin: 115.43479
  Tmin: 1201955445
  step: 100

  minfreq: 50
  max_grid_size: 20000
  k: 1
  grid_start: 4

  max_length: 500
  overlap: 100
  load_graph: True
  load_emb: True


  gridemb_dim: 128
  context_size: 10
  walks_per_node: 10
  walk_length: 80
  num_workers: 2
  gridemb_lr: 0.01
  gridemb_epochs: 1000


  n_train_start: 0
  n_train: 1000
  max_train_len: 2000

  batch_size: 32
  device: 'cpu'

  Bert:
    encoding_type: 'temporal'
    ctle_num_layers: 4
    ctle_num_heads: 8
    ctle_mask_prop: 0.2
    ctle_detach: False
    ctle_objective: 'mlm'
    ctle_static: False
    embed_size: 128
    max_seq_len: 500
    init_param: False
    embed_epoch: 2000
    grid_size: 20004
    pretain_path: './ModelSave/T-drive/pretrain/Bert_100_100_50_20000'
    device: 'cpu'

  GAT:
    in_features: 128
    out_features: 32
    num_heads: 4
    lr: 1e-4
    wd: 0.0
    batch_size: 64
    num_epoch: 20
    lambda1: 0.3
    lambda2: 0.5
    lambda3: 1
    save_path: './ModelSave/T-drive/GraphSimp_100_100_50_20000'

  Diff:

    wd: 0.0
    batch_size: 64


    schedule_sampler: "uniform"
    lr: 1e-4
    ema_rate: "0.9999" # comma-separated list of EMA values
    log_interval: 50
    save_interval: 50000
    resume_checkpoint: ""
    use_fp16: False
    fp16_scale_growth: 1e-3
    weight_decay: 0.0
    lr_anneal_steps: 0
    checkpoint_path: 'diff_models'
    gradient_clipping: -1.0
    eval_interval: 2000
    epochs: 20
    lambda1: 0.7

    in_dim: 4
    encoder_n_head: 2
    encoder_hidden_dim: 128
    encoder_n_layer: 2
    in_channels: 128
    hidden_channels: 256
    out_channels: 128
    n_head: 2
    n_layer: 2
    trans_hidden_channels: 256
    attn_dropout: 0.1
    dropout: 0.1

    learn_sigma: False
    sigma_small: False
    diffusion_steps: 2000
    noise_schedule: 'linear'
    timestep_respacing: ''
    use_kl: False
    predict_xstart: False
    rescale_timesteps: True
    rescale_learned_sigmas: True
    training_mode: 'e2e'

    amplify_len: 20
    diff_step_eval: 500


  ad_ratio: 0.7
  cr: [0.0025,0.003,0.0035,0.004,0.0045,0.01,0.02]
  mutual_epochs: 10





OSM:

  dataset: 'OSM'
  out_dir: 'ModelSave'
  result_dir: 'SimpTraj'
  nostdout: True
  gpu: 7
  seed: 0


  load_grid: True
  minlon: 8.08
  minlat: 54.56
  maxlon: 15.19
  maxlat: 57.75
  maxseqlen: 5000
  minseqlen: 500
  Xmin: 54.56
  Ymin: 8.08
  Tmin: 1176587085
  step: 500

  minfreq: 50
  max_grid_size: 20000
  k: 1
  grid_start: 4

  max_length: 500
  overlap: 100
  load_graph: True
  load_emb: True


  gridemb_dim: 128
  context_size: 10
  walks_per_node: 10
  walk_length: 80
  num_workers: 2
  gridemb_lr: 0.01
  gridemb_epochs: 1000


  n_train_start: 0
  n_train: 1000
  max_train_len: 2000

  batch_size: 32
  device: 'cpu'

  Bert:
    encoding_type: 'temporal'
    ctle_num_layers: 4
    ctle_num_heads: 8
    ctle_mask_prop: 0.2
    ctle_detach: False
    ctle_objective: 'mlm'
    ctle_static: False
    embed_size: 128
    max_seq_len: 500
    init_param: False
    embed_epoch: 2000
    grid_size: 20004
    pretain_path: './ModelSave/OSM/pretrain/Bert_500_500_50_20000'
    device: 'cpu'

  GAT:
    in_features: 128
    out_features: 32
    num_heads: 4
    lr: 1e-4
    wd: 0.0
    batch_size: 64
    num_epoch: 20
    lambda1: 0.3
    lambda2: 0.5
    lambda3: 1
    save_path: './ModelSave/OSM/GraphSimp_500_500_50_20000'

  Diff:

    wd: 0.0
    batch_size: 64


    schedule_sampler: "uniform"
    lr: 1e-4
    ema_rate: "0.9999" # comma-separated list of EMA values
    log_interval: 50
    save_interval: 50000
    resume_checkpoint: ""
    use_fp16: False
    fp16_scale_growth: 1e-3
    weight_decay: 0.0
    lr_anneal_steps: 0
    checkpoint_path: 'diff_models'
    gradient_clipping: -1.0
    eval_interval: 2000
    epochs: 20
    lambda1: 0.7

    in_dim: 4
    encoder_n_head: 2
    encoder_hidden_dim: 128
    encoder_n_layer: 2
    in_channels: 128
    hidden_channels: 256
    out_channels: 128
    n_head: 2
    n_layer: 2
    trans_hidden_channels: 256
    attn_dropout: 0.1
    dropout: 0.1

    learn_sigma: False
    sigma_small: False
    diffusion_steps: 2000
    noise_schedule: 'linear'
    timestep_respacing: ''
    use_kl: False
    predict_xstart: False
    rescale_timesteps: True
    rescale_learned_sigmas: True
    training_mode: 'e2e'

    amplify_len: 20
    diff_step_eval: 500


  ad_ratio: 0.5
  cr: [0.0025,0.003,0.0035,0.004,0.0045,0.01,0.02]
  mutual_epochs: 10